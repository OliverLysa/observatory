{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5192e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading UK gov. data...\n",
      "UK gov. data downloaded: 470134 lines\n",
      "           BodyType    Make       GenModel                 Model  \\\n",
      "0              Cars  ABARTH     ABARTH 124       124 GT MULTIAIR   \n",
      "1              Cars  ABARTH     ABARTH 124       124 GT MULTIAIR   \n",
      "2              Cars  ABARTH     ABARTH 124  124 GT MULTIAIR AUTO   \n",
      "3              Cars  ABARTH     ABARTH 124  124 GT MULTIAIR AUTO   \n",
      "4              Cars  ABARTH  ABARTH SPIDER   124 SPIDER MULTIAIR   \n",
      "...             ...     ...            ...                   ...   \n",
      "470128  Motorcycles  ZONTES      ZONTES ZT             ZT 125-G1   \n",
      "470129  Motorcycles  ZONTES      ZONTES ZT              ZT 125-U   \n",
      "470130  Motorcycles  ZONTES      ZONTES ZT              ZT 125-U   \n",
      "470131  Motorcycles  ZONTES      ZONTES ZT             ZT 125-U1   \n",
      "470132  Motorcycles  ZONTES      ZONTES ZT             ZT 125-U1   \n",
      "\n",
      "       YearFirstUsed YearManufacture  Licensed  SORN  \n",
      "0               2019            2019         5     3  \n",
      "1               2018            2018        11     0  \n",
      "2               2019            2019        12     2  \n",
      "3               2018            2018        14     1  \n",
      "4               2019            2019        31     3  \n",
      "...              ...             ...       ...   ...  \n",
      "470128          2020            2020        10     2  \n",
      "470129          2021            2021       199     1  \n",
      "470130          2020            2020        16     1  \n",
      "470131          2021            2021       249     1  \n",
      "470132          2020            2020         2     1  \n",
      "\n",
      "[470133 rows x 8 columns]\n",
      "Done and saved\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import os\n",
    "import csv\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=DeprecationWarning)\n",
    "from bs4 import BeautifulSoup  # library to parse HTML documents\n",
    "import json\n",
    "import re\n",
    "import requests\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# blacklist: words and symbols to ignore.Should be lowercased\n",
    "blacklist = ['s-a', '!', ':', '-', '_', 'â€“', '|', '#', 'quattro', 'sportback', 'quattro auto', '4matic', 'awd',\n",
    "             'x-drive', 'edition 1', 's line', 'tfsi', 'tdi', 'mhev']\n",
    "\n",
    "# please set this value to True if you want to update the first data source file cars.csv\n",
    "update_evspecifications = False\n",
    "\n",
    "# URL of the UK GOV data\n",
    "data_source_url = 'https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1077524/df_VEH0124.csv'\n",
    "\n",
    "# output file name\n",
    "output_file_name = 'output_v4.csv'\n",
    "\n",
    "# list of columns to add to the output df. Please be careful with column names.\n",
    "columns_to_add = ['Electric motor_Electric motor type', 'Electric motor_Location of the motor', 'Electric motor_Power',\n",
    "                  'Electric motor_Torque', 'Second electric motor_Motor type', 'Second electric motor_Location',\n",
    "                  'Second electric motor_Power', 'Second electric motor_Torque',\n",
    "                  'Second electric motor_Regenerative braking']\n",
    "\n",
    "# please sett to True if you need to save 'matched' values only\n",
    "save_matched_only = True\n",
    "\n",
    "\n",
    "def save_csv(data, filename):\n",
    "    \"\"\"\n",
    "    :param csv_inputs:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, \"w\", encoding='utf-8', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(data)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(\"File {} not found or format is wrong\".format(filename))\n",
    "\n",
    "\n",
    "def get_gov_data(data_source_url):\n",
    "    \"\"\"\n",
    "    Downloads UK gov.data by the link and returns as a list of lists\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print_log(\"Downloading UK gov. data...\")\n",
    "        response = requests.get(data_source_url)\n",
    "        gov_data_list = list(csv.reader(response.content.decode('latin1').splitlines(), delimiter=','))\n",
    "        print_log(\"UK gov. data downloaded: {} lines\".format(len(gov_data_list)))\n",
    "        return gov_data_list\n",
    "    except Exception as e:\n",
    "        print_log(\"Exception in get_gov_data {}\".format(str(e)))\n",
    "        print_log(traceback.format_exc())\n",
    "\n",
    "\n",
    "def get_brands(headers):\n",
    "    \"\"\"\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "\n",
    "        while True:\n",
    "            try:\n",
    "\n",
    "                response = requests.get(\"https://www.evspecifications.com/\", headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    break\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        brands = []\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        for brand in soup.find(\"div\", {\"class\": \"brand-listing-container-frontpage\"}).find_all(\"a\"):\n",
    "            brand_name = brand.text\n",
    "            brand_url = brand[\"href\"]\n",
    "            print(\" \" + brand_name + \" : \" + brand_url)\n",
    "            brands.append([brand_name, brand_url])\n",
    "\n",
    "        return brands\n",
    "    except Exception as e:\n",
    "        print_log(\"Exception in get_brands {}\".format(str(e)))\n",
    "        print_log(traceback.format_exc())\n",
    "\n",
    "\n",
    "def get_models(brand, headers):\n",
    "    \"\"\"\n",
    "    :param brand:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "\n",
    "                response = requests.get(brand[1], headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    break\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        regex = re.compile(\"model_.*\")\n",
    "\n",
    "        models = []\n",
    "        for model in soup.find_all(\"div\", {\"id\": regex}):\n",
    "            model_url = model.find(\"a\")[\"href\"]\n",
    "            models.append([brand[0], brand[1], model_url])\n",
    "\n",
    "        return models\n",
    "    except Exception as e:\n",
    "        print_log(\"Exception in get_models {}\".format(str(e)))\n",
    "        print_log(traceback.format_exc())\n",
    "\n",
    "\n",
    "def fetch_model(model, headers):\n",
    "    \"\"\"\n",
    "    :param model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        while True:\n",
    "            try:\n",
    "\n",
    "                response = requests.get(model[2], headers=headers)\n",
    "                if response.status_code == 200:\n",
    "                    break\n",
    "\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        html = response.text\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "        model_name = soup.find(\"h1\").text.split(\"- Specifications\")[0].strip()\n",
    "        car_image = soup.find(\"div\", {\"id\": \"model-image\"})[\"style\"].split(\"url(\")[1].split(\");\")[0]\n",
    "\n",
    "        car_details = {\n",
    "\n",
    "            \"Brand Name\": model[0],\n",
    "            \"Brand URL\": model[1],\n",
    "            \"Model Name\": model_name,\n",
    "            \"Model URL\": model[2],\n",
    "            \"Car Image\": car_image\n",
    "\n",
    "        }\n",
    "        brief_specifications = soup.find(\"div\", {\"id\": \"model-brief-specifications\"}).find_all(\"b\")\n",
    "\n",
    "        for specification in brief_specifications:\n",
    "\n",
    "            specification_key = specification.text.strip()\n",
    "            specification_value = specification.next.next.strip().split(\":\")[1].strip()\n",
    "\n",
    "            if specification_value[-1] == \",\":\n",
    "                specification_value = specification_value[:-1]\n",
    "\n",
    "            if specification_key in car_details:\n",
    "                specification_key = specification_key + \"_2\"\n",
    "\n",
    "            car_details[specification_key] = specification_value\n",
    "\n",
    "        tables = soup.find_all(\"table\", {\"class\": \"model-information-table row-selection\"})\n",
    "\n",
    "        headers_list = [\n",
    "            \"Brand, model, trim, price\",\n",
    "            \"Body style, dimensions, volumes, weights.\",\n",
    "            \"Electric motor\",\n",
    "            \"Second electric motor\",\n",
    "            \"Performance\",\n",
    "            \"Steering\",\n",
    "            \"Transmission\",\n",
    "            \"Suspension\",\n",
    "            \"Brakes\",\n",
    "            \"Battery\",\n",
    "\n",
    "        ]\n",
    "        for table in tables:\n",
    "\n",
    "            header = table.find_previous(\"header\").find(\"h2\").text.strip()\n",
    "            if header in headers_list:\n",
    "                for tr in table.find_all(\"tr\"):\n",
    "                    specification_key = header + \"_\" + tr.find_all(\"td\")[0].find(\"p\").previous.strip()\n",
    "                    specification_value = tr.find_all(\"td\")[1].text.strip()\n",
    "                    car_details[specification_key] = specification_value\n",
    "\n",
    "        return car_details\n",
    "    except Exception as e:\n",
    "        print_log(\"Exception in fetch_model {}\".format(str(e)))\n",
    "        print_log(traceback.format_exc())\n",
    "\n",
    "\n",
    "def update_evspecifications_data():\n",
    "    \"\"\"\n",
    "    updates evspecifications data an saves to cars.csv\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print_log(\"Updating evspecifications data (cars.csv)...\")\n",
    "        headers = {\n",
    "            'accept': 'application/json, text/plain, */*',\n",
    "            'accept-language': 'en-US,en;q=0.9,ar-TN;q=0.8,ar;q=0.7',\n",
    "            'cache-control': 'no-cache',\n",
    "            'origin': 'https://www.evspecifications.com/',\n",
    "            'pragma': 'no-cache',\n",
    "            'referer': 'https://www.evspecifications.com/',\n",
    "            'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36',\n",
    "        }\n",
    "        brands = get_brands(headers)\n",
    "        cars = []\n",
    "        for brand in brands:\n",
    "\n",
    "            models = get_models(brand, headers)\n",
    "            for model in models:\n",
    "                car_details = fetch_model(model, headers)\n",
    "                print(car_details)\n",
    "                cars.append(car_details)\n",
    "        keys = [i for s in [d.keys() for d in cars] for i in s]\n",
    "        with open(\"cars.json\", 'w', encoding='utf-8') as outfile:\n",
    "            json.dump(cars, outfile, sort_keys=False, indent=4, ensure_ascii=False)\n",
    "        df = pd.read_json(\"cars.json\")\n",
    "        df.to_csv(\"cars.csv\", index=None)\n",
    "    except Exception as e:\n",
    "        print_log(\"Exception in update_evspecifications_data {}\".format(str(e)))\n",
    "        print_log(traceback.format_exc())\n",
    "\n",
    "\n",
    "def print_log(msg: str):\n",
    "    \"\"\"\n",
    "    print message and wries to LOG.txt\n",
    "    :param msg:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(msg)\n",
    "        now = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        with open(\"LOG.txt\", 'a+', encoding='utf-8') as f:\n",
    "            f.write('[{}] {}\\n'.format(now, msg))\n",
    "    except Exception as e:\n",
    "        print(traceback.format_exc())\n",
    "\n",
    "\n",
    "def create_tricky_model(x):\n",
    "    if len(x['tricky_model'].split()) >= 2:\n",
    "        result = ''.join(x['tricky_model'].split()[:2]) + ''.join(\n",
    "            [element for element in x['tricky_model'].split()[2:] if element.isnumeric() or element[0] in ['e', 'i']])\n",
    "    else:\n",
    "        result = ''.join(x['tricky_model'].split()[:1]) + ''.join(\n",
    "            [element for element in x['tricky_model'].split()[1:] if element.isnumeric() or element[0] in ['e', 'i']])\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    the main pileline\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # removing LOG file of previous session if exists.\n",
    "        if os.path.exists(\"LOG.txt\"):\n",
    "            os.remove(\"LOG.txt\")\n",
    "\n",
    "        # getting the UK gov data\n",
    "        gov_data = get_gov_data(data_source_url)\n",
    "        # saving to csv\n",
    "        save_csv(gov_data, 'gov_data.csv')\n",
    "        gov_data_df = pd.read_csv('gov_data.csv')\n",
    "\n",
    "        print(gov_data_df)\n",
    "        # getting the first data source data if  specified\n",
    "        if update_evspecifications:\n",
    "            update_evspecifications_data()\n",
    "        cars_data_df = pd.read_csv('cars.csv')\n",
    "\n",
    "        cars_data_df['tricky_model'] = cars_data_df['Brand, model, trim, price_Model'].astype(str).str.lower()\n",
    "        cars_data_df['tricky_model'] = cars_data_df.apply(create_tricky_model, axis=1)\n",
    "\n",
    "        # creating a special key to merge df's case insensitive\n",
    "        cars_data_df['cars_key'] = cars_data_df['Brand, model, trim, price_Model year'].astype(str).str.lower() + ' ' + \\\n",
    "                                   cars_data_df[\n",
    "                                       'Brand, model, trim, price_Brand'].astype(str).str.lower() + ' ' + cars_data_df[\n",
    "                                       'tricky_model'].astype(str).str.lower()\n",
    "\n",
    "        cars_data_df = cars_data_df.drop('tricky_model', axis=1)\n",
    "\n",
    "        for blacklist_symbol in blacklist:\n",
    "            cars_data_df['cars_key'] = cars_data_df['cars_key'].astype(str).str.replace(blacklist_symbol, '')\n",
    "\n",
    "        cars_data_df['cars_key'] = cars_data_df['cars_key'].astype(str).str.replace(' ', '')\n",
    "\n",
    "        columns_to_add.append('cars_key')\n",
    "        # filtering columns to add\n",
    "        cars_data_df = cars_data_df[columns_to_add]\n",
    "\n",
    "        gov_data_df['tricky_model'] = gov_data_df['Model'].astype(str).str.lower()\n",
    "        gov_data_df['tricky_model'] = gov_data_df.apply(create_tricky_model, axis=1)\n",
    "\n",
    "        # creating a special key to merge df's case insensitive\n",
    "        gov_data_df['gov_key'] = gov_data_df['YearFirstUsed'].astype(str).str.lower() + ' ' + gov_data_df[\n",
    "            'Make'].astype(str).str.lower() + ' ' + gov_data_df['tricky_model'].astype(str).str.lower()\n",
    "\n",
    "        for blacklist_symbol in blacklist:\n",
    "            gov_data_df['gov_key'] = gov_data_df['gov_key'].astype(str).str.replace(blacklist_symbol, '')\n",
    "        gov_data_df['gov_key'] = gov_data_df['gov_key'].astype(str).str.replace(' ', '')\n",
    "\n",
    "        gov_data_df = gov_data_df.drop('tricky_model', axis=1)\n",
    "\n",
    "        if save_matched_only:\n",
    "            mode = 'inner'\n",
    "        else:\n",
    "            mode = 'left'\n",
    "        # joining DF's\n",
    "        result_df = gov_data_df.merge(cars_data_df, left_on='gov_key', right_on='cars_key', how=mode,\n",
    "                                      indicator=False)\n",
    "        # removing key rows\n",
    "        result_df = result_df.drop('gov_key', axis=1)\n",
    "        result_df = result_df.drop('cars_key', axis=1)\n",
    "\n",
    "        # save results\n",
    "        result_df.to_csv(output_file_name, index=False)\n",
    "        print_log(\"Done and saved\")\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print_log(str(e))\n",
    "        print_log(traceback.format_exc())\n",
    "\n",
    "\n",
    "# we should check if the method is main to call it from other scripts and threds\n",
    "if __name__ == '__main__':\n",
    "    # freeze support allows to use multiprocessing on Windows\n",
    "    multiprocessing.freeze_support()\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
